# CrewAI configuration
OPENAI_API_KEY=

OPENROUTER_API_KEY=
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"

AGENT_MAIN_MODEL="openai/gpt-4.1-mini"
AGENT_TOOL_CALL_MODEL="openai/gpt-4.1-mini"
TOOL_MODEL="openai/gpt-4.1-mini"
GUARDRAIL_MODEL="openai/gpt-4.1-nano"

CREWAI_STORAGE_DIR="./memory"

# Weaviate configuration
WEAVIATE_API_KEY=
WEAVIATE_HOST="127.0.0.1"
WEAVIATE_PORT="8080"
WEAVIATE_GRPC_PORT="50051"

# Late chunking configuration
LATE_CHUNKING_MODEL_NAME="jinaai/jina-embeddings-v3"
LATE_CHUNKING_HEADERS_TO_SPLIT_ON=[("#", "h1"), ("##", "h2")] 
LATE_CHUNKING_MAX_CHUNK_CHARS=2048
LATE_CHUNKING_DEVICE="cuda"

# Ingest configuration
INGEST_KNOWLEDGE_SUMMARY_MODEL="gpt-4.1-nano"
INGEST_KNOWLEDGE_CONFIG_PATH="config/knowledge/knowledge.yaml"
INGEST_KNOWLEDGE_OVERRIDE_COLLECTION=True

# Temp files directory
TEMP_FILES_DIR="temp" # this is were the config files are stored during the flow execution

# config files directory
CONFIG_FILES_DIR="config" # this is were the config files are stored

# Kubectl configuration
KUBECTL_PATH="C:\\Program Files\\Docker\\Docker\\resources\\bin\\kubectl.exe"
KUBECTL_ALLOWED_VERBS="get,describe,logs,apply,diff,delete,create,patch,exec,cp,rollout,scale"
KUBECTL_SAFE_NAMESPACES=""
KUBECTL_DENIED_NAMESPACES="kube-system,kube-public"
KUBECTL_DENY_FLAGS="--raw,--kubeconfig,--context,-ojsonpath,--output"

# K8s version
K8S_VERSION="v1.29.0"

#StackExchange API Key
STACK_EXCHANGE_API_KEY=

#BraveSearch API Key
BRAVE_API_KEY=



# Popeye configuration
POPEYE_PATH="D:\\Python\\MasterIA\\TFM\\TFM\\Popeye\\popeye.exe"