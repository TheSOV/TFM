{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7446d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cfb4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.late_chunking:Initialized LateChunkingHelper: device=cuda, max_chunk_chars=2048\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: jinaai/jina-embeddings-v3\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "WARNING:transformers_modules.jinaai.xlm-roberta-flash-implementation.2b6bc3f30750b3a9648fe9b63448c09920efe9be.modeling_xlm_roberta:flash_attn is not installed. Using PyTorch native attention implementation.\n",
      "INFO:sentence_transformers.SentenceTransformer:5 prompts are loaded, with the keys: ['retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching']\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()                      # 1️⃣  make env-vars visible\n",
    "\n",
    "from src.containers import Container   # 2️⃣  class body reads env once\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "container = Container()            # 3️⃣  build the container\n",
    "\n",
    "weaviate_helper      = container.weaviate_helper()\n",
    "late_chunking_helper = container.late_chunking_helper()\n",
    "ingest_helper = container.ingest_helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc4a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_helper._scan_and_get_directories(\"knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\", {\"include\": [\"yaml\", \"yml\"], \"exclude\": [], \"min_length\": 0, \"max_length\": -1, \"generate_summary\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c156a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with weaviate_helper.connect() as client:\n",
    "    collection = client.collections.get(name=\"kubernetes_code\")\n",
    "    for obj in collection.iterator():\n",
    "        print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9333cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_helper.ingest_knowledge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e5afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with weaviate_helper.connect() as client:\n",
    "    client.collections.delete(name=\"test\")\n",
    "\n",
    "weaviate_helper.create_collection(collection_name=\"test\", description=\"test description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8718c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, canonical_doc = late_chunking_helper.chunk_file(\n",
    "    path=\"knowledge/kubernetes/website-main/content/en/docs/reference/kubectl/quick-reference.md\",\n",
    ")\n",
    "docs = late_chunking_helper.generate_late_chunking_embeddings(docs, canonical_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9813ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:8080/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:8080/v1/schema/Test \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "weaviate_helper.batch_insert(docs, collection_name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f37c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.late_chunking:generate_query_embedding: query='how to design a deployment with horizontal scaling'\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:8080/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:8080/v1/schema/Kubernetes_code \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how to design a deployment with horizontal scaling\"\n",
    "query_embedding = late_chunking_helper.generate_query_embedding(query)\n",
    "rag_results = weaviate_helper.rag_query(collection_name=\"kubernetes_code\", query_embedding=query_embedding, limit=25)\n",
    "rag_results = [rag_result.properties for rag_result in rag_results]\n",
    "len(rag_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbc2fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.embeddings.late_chunking:re_rank: 100 docs, top_k=10\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.34it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.17it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.32it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.79it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.28it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.57it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.26it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.19it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.29it/s]\n",
      "INFO:src.embeddings.late_chunking:re_rank: returning 10 ranked docs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'doc': {'content': '# This YAML configuration defines a Kubernetes Horizontal Pod Autoscaler (HPA) for the \"frontend\" application. It automatically adjusts the number of pod replicas based on CPU utilization, aiming to keep it around 50%. The HPA targets a ReplicaSet named \"frontend\" and maintains a minimum of 3 pods and a maximum of 10 pods. This setup enables dynamic scaling of the application to handle varying workloads efficiently, ensuring optimal performance without over-provisioning.\\napiVersion: autoscaling/v1\\nkind: HorizontalPodAutoscaler\\nmetadata:\\n  name: frontend-scaler\\nspec:\\n  scaleTargetRef:\\n    kind: ReplicaSet\\n    name: frontend\\n  minReplicas: 3\\n  maxReplicas: 10\\n  targetCPUUtilizationPercentage: 50\\n',\n",
       "   'subchunk': '1/1',\n",
       "   'summary': 'This YAML configuration defines a Kubernetes Horizontal Pod Autoscaler (HPA) for the \"frontend\" application. It automatically adjusts the number of pod replicas based on CPU utilization, aiming to keep it around 50%. The HPA targets a ReplicaSet named \"frontend\" and maintains a minimum of 3 pods and a maximum of 10 pods. This setup enables dynamic scaling of the application to handle varying workloads efficiently, ensuring optimal performance without over-provisioning.',\n",
       "   'chunk': '1/1',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\\\\controllers\\\\hpa-rs.yaml'},\n",
       "  'score': 0.78125},\n",
       " {'doc': {'content': '# This content describes a Kubernetes HorizontalPodAutoscaler configuration, which automatically adjusts the number of pod replicas based on workload demand. The autoscaler targets a deployment named \"php-apache\" with a replica count ranging between 1 and 10 pods. It monitors CPU utilization, aiming to maintain an average usage of 50%. When CPU usage exceeds this threshold, the autoscaler increases the number of pods, and it scales down when utilization drops below the target, ensuring efficient resource utilization and application availability.\\napiVersion: autoscaling/v2\\nkind: HorizontalPodAutoscaler\\nmetadata:\\n  name: php-apache\\nspec:\\n  scaleTargetRef:\\n    apiVersion: apps/v1\\n    kind: Deployment\\n    name: php-apache\\n  minReplicas: 1\\n  maxReplicas: 10\\n  metrics:\\n  - type: Resource\\n    resource:\\n      name: cpu\\n      target:\\n        type: Utilization\\n        averageUtilization: 50\\n',\n",
       "   'subchunk': '1/1',\n",
       "   'summary': 'This content describes a Kubernetes HorizontalPodAutoscaler configuration, which automatically adjusts the number of pod replicas based on workload demand. The autoscaler targets a deployment named \"php-apache\" with a replica count ranging between 1 and 10 pods. It monitors CPU utilization, aiming to maintain an average usage of 50%. When CPU usage exceeds this threshold, the autoscaler increases the number of pods, and it scales down when utilization drops below the target, ensuring efficient resource utilization and application availability.',\n",
       "   'chunk': '1/1',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\\\\application\\\\hpa\\\\php-apache.yaml'},\n",
       "  'score': 0.76953125},\n",
       " {'doc': {'content': '# This YAML configuration defines a Horizontal Pod Autoscaler (HPA) for a Kubernetes deployment named \"nginx.\" The HPA monitors the CPU utilization of the deployment and automatically adjusts the number of pod replicas between 1 and 10 based on resource demand. Specifically, it aims to keep the average CPU utilization across pods at around 20%. If CPU usage exceeds this target, the HPA scales up the number of pods; if it drops below, it scales down, ensuring efficient resource utilization and maintaining application performance.\\napiVersion: autoscaling/v2beta1\\nkind: HorizontalPodAutoscaler\\nmetadata:\\n  name: nginx\\n  namespace:\\n  labels:\\nspec:\\n  scaleTargetRef:\\n    apiVersion: extensions/v1beta1\\n    kind: Deployment\\n    name: nginx\\n  minReplicas: 1\\n  maxReplicas: 10\\n  metrics:\\n  - type: Resource\\n    resource:\\n      name: cpu\\n      targetAverageUtilization: 20\\n',\n",
       "   'chunk': '1/1',\n",
       "   'summary': 'This YAML configuration defines a Horizontal Pod Autoscaler (HPA) for a Kubernetes deployment named \"nginx.\" The HPA monitors the CPU utilization of the deployment and automatically adjusts the number of pod replicas between 1 and 10 based on resource demand. Specifically, it aims to keep the average CPU utilization across pods at around 20%. If CPU usage exceeds this target, the HPA scales up the number of pods; if it drops below, it scales down, ensuring efficient resource utilization and maintaining application performance.',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\kubernetes-lab-tutorial-master\\\\examples\\\\monitoring\\\\nginx-hpa.yaml',\n",
       "   'subchunk': '1/1'},\n",
       "  'score': 0.76171875},\n",
       " {'doc': {'content': '# This content describes a Kubernetes Deployment configuration in YAML format. It defines a deployment named \"nginx-deployment\" that manages four replicas of an Nginx web server container, indicating an increase from a previous count of two. The deployment uses the \"nginx:1.16.1\" image and exposes port 80 within each container. The configuration includes metadata for identification, a selector for matching the pods, and a template that specifies the container details, ensuring consistent deployment and scaling of the application.\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: nginx-deployment\\nspec:\\n  selector:\\n    matchLabels:\\n      app: nginx\\n  replicas: 4 # Update the replicas from 2 to 4\\n  template:\\n    metadata:\\n      labels:\\n        app: nginx\\n    spec:\\n      containers:\\n      - name: nginx\\n        image: nginx:1.16.1\\n        ports:\\n        - containerPort: 80\\n',\n",
       "   'subchunk': '1/1',\n",
       "   'summary': 'This content describes a Kubernetes Deployment configuration in YAML format. It defines a deployment named \"nginx-deployment\" that manages four replicas of an Nginx web server container, indicating an increase from a previous count of two. The deployment uses the \"nginx:1.16.1\" image and exposes port 80 within each container. The configuration includes metadata for identification, a selector for matching the pods, and a template that specifies the container details, ensuring consistent deployment and scaling of the application.',\n",
       "   'chunk': '1/1',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\\\\application\\\\deployment-scale.yaml'},\n",
       "  'score': 0.76171875},\n",
       " {'doc': {'content': '# The provided content is a Kubernetes deployment configuration written in YAML. It defines a deployment named \"snowflake\" using the `apps/v1` API version, which manages how containerized applications are run and scaled in a Kubernetes cluster. The deployment specifies that two replicas of the container should be maintained, ensuring high availability. The container uses the `registry.k8s.io/serve_hostname` image with a policy to always pull the latest version, and it is labeled with \"app: snowflake\" for easy identification and management within the cluster. Overall, this configuration automates the deployment and scaling of a simple containerized application in Kubernetes.\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  labels:\\n    app: snowflake\\n  name: snowflake\\nspec:\\n  replicas: 2\\n  selector:\\n    matchLabels:\\n      app: snowflake\\n  template:\\n    metadata:\\n      labels:\\n        app: snowflake\\n    spec:\\n      containers:\\n      - image: registry.k8s.io/serve_hostname\\n        imagePullPolicy: Always\\n        name: snowflake\\n',\n",
       "   'chunk': '1/1',\n",
       "   'summary': 'The provided content is a Kubernetes deployment configuration written in YAML. It defines a deployment named \"snowflake\" using the `apps/v1` API version, which manages how containerized applications are run and scaled in a Kubernetes cluster. The deployment specifies that two replicas of the container should be maintained, ensuring high availability. The container uses the `registry.k8s.io/serve_hostname` image with a policy to always pull the latest version, and it is labeled with \"app: snowflake\" for easy identification and management within the cluster. Overall, this configuration automates the deployment and scaling of a simple containerized application in Kubernetes.',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\\\\admin\\\\snowflake-deployment.yaml',\n",
       "   'subchunk': '1/1'},\n",
       "  'score': 0.76171875},\n",
       " {'doc': {'content': '# This content is a Kubernetes deployment configuration written in YAML. It describes deploying an application called \"hello-world\" with two replicas for load balancing. The deployment specifies a selector based on the label \"run: load-balancer-example\" to manage the pods. Each pod runs a container from the image \"us-docker.pkg.dev/google-samples/containers/gke/hello-app:2.0\" and exposes port 8080 over TCP. The configuration ensures high availability by running multiple instances of the application, facilitating easy scaling and management within a Kubernetes cluster.\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: hello-world\\nspec:\\n  selector:\\n    matchLabels:\\n      run: load-balancer-example\\n  replicas: 2\\n  template:\\n    metadata:\\n      labels:\\n        run: load-balancer-example\\n    spec:\\n      containers:\\n        - name: hello-world\\n          image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:2.0\\n          ports:\\n            - containerPort: 8080\\n              protocol: TCP\\n',\n",
       "   'subchunk': '1/1',\n",
       "   'summary': 'This content is a Kubernetes deployment configuration written in YAML. It describes deploying an application called \"hello-world\" with two replicas for load balancing. The deployment specifies a selector based on the label \"run: load-balancer-example\" to manage the pods. Each pod runs a container from the image \"us-docker.pkg.dev/google-samples/containers/gke/hello-app:2.0\" and exposes port 8080 over TCP. The configuration ensures high availability by running multiple instances of the application, facilitating easy scaling and management within a Kubernetes cluster.',\n",
       "   'chunk': '1/1',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\\\\service\\\\access\\\\hello-application.yaml'},\n",
       "  'score': 0.7578125},\n",
       " {'doc': {'content': '# This configuration defines a Kubernetes Deployment named \"pod-quota-demo\" that manages three replicas of an Nginx container. The Deployment uses a selector to target pods labeled with \"purpose: quota-demo\" and ensures that three identical pods are running at all times. The primary function of this configuration is to deploy and maintain a scalable set of Nginx web server pods, which can be useful in scenarios requiring load balancing or high availability. The setup allows easy management and updates of these pods within a Kubernetes cluster.\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: pod-quota-demo\\nspec:\\n  selector:\\n    matchLabels:\\n      purpose: quota-demo\\n  replicas: 3\\n  template:\\n    metadata:\\n      labels:\\n        purpose: quota-demo\\n    spec:\\n      containers:\\n      - name: pod-quota-demo\\n        image: nginx\\n',\n",
       "   'chunk': '1/1',\n",
       "   'summary': 'This configuration defines a Kubernetes Deployment named \"pod-quota-demo\" that manages three replicas of an Nginx container. The Deployment uses a selector to target pods labeled with \"purpose: quota-demo\" and ensures that three identical pods are running at all times. The primary function of this configuration is to deploy and maintain a scalable set of Nginx web server pods, which can be useful in scenarios requiring load balancing or high availability. The setup allows easy management and updates of these pods within a Kubernetes cluster.',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\\\\admin\\\\resource\\\\quota-pod-deployment.yaml',\n",
       "   'subchunk': '1/1'},\n",
       "  'score': 0.75390625},\n",
       " {'doc': {'content': '# This content is a Kubernetes Deployment configuration in YAML, designed to manage the deployment of a pod called \"capacity-reservation.\" It specifies a single replica pod using the \"apps/v1\" API version, with metadata including the deployment\\'s name and labels for selectivity. The deployment template defines labels and annotations for description and specifies a priority class, which can influence scheduling order.\\n\\nThe spec includes an affinity rule to enhance pod distribution across nodes, specifically using a \"podAntiAffinity\" strategy. This rule prefers to place pods with certain labels on different nodes to optimize resource utilization and fault tolerance. The container named \"pause\" uses the \"registry.k8s.io/pause:3.6\" image, which is often used as a lightweight placeholder container to reserve capacity or set up network tools. It requests minimal CPU (\"50m\") and 512MiB of memory, and caps memory limits to 512MiB.\\n\\nOverall, the configuration is designed to reserve capacity on the cluster efficiently, ensuring the pod is scheduled with considerations for node distribution and resource requests, using a lightweight container.\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: capacity-reservation\\n  # You should decide what namespace to deploy this into\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app.kubernetes.io/name: capacity-placeholder\\n  template:\\n    metadata:\\n      labels:\\n        app.kubernetes.io/name: capacity-placeholder\\n      annotations:\\n        kubernetes.io/description: \"Capacity reservation\"\\n    spec:\\n      priorityClassName: placeholder\\n      affinity: # Try to place these overhead Pods on different nodes\\n                # if possible\\n        podAntiAffinity:\\n          preferredDuringSchedulingIgnoredDuringExecution:\\n          - labelSelector:\\n              matchLabels:\\n                app: placeholder\\n            topologyKey: \"kubernetes.io/hostname\"\\n      containers:\\n      - name: pause\\n        image: registry.k8s.io/pause:3.6\\n        resources:\\n          requests:\\n            cpu: \"50m\"\\n            memory: \"512Mi\"\\n          limits:\\n            memory: \"512Mi\"\\n',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\\\\deployments\\\\deployment-with-capacity-reservation.yaml',\n",
       "   'summary': 'This content is a Kubernetes Deployment configuration in YAML, designed to manage the deployment of a pod called \"capacity-reservation.\" It specifies a single replica pod using the \"apps/v1\" API version, with metadata including the deployment\\'s name and labels for selectivity. The deployment template defines labels and annotations for description and specifies a priority class, which can influence scheduling order.\\n\\nThe spec includes an affinity rule to enhance pod distribution across nodes, specifically using a \"podAntiAffinity\" strategy. This rule prefers to place pods with certain labels on different nodes to optimize resource utilization and fault tolerance. The container named \"pause\" uses the \"registry.k8s.io/pause:3.6\" image, which is often used as a lightweight placeholder container to reserve capacity or set up network tools. It requests minimal CPU (\"50m\") and 512MiB of memory, and caps memory limits to 512MiB.\\n\\nOverall, the configuration is designed to reserve capacity on the cluster efficiently, ensuring the pod is scheduled with considerations for node distribution and resource requests, using a lightweight container.',\n",
       "   'subchunk': '1/1',\n",
       "   'chunk': '1/1'},\n",
       "  'score': 0.75},\n",
       " {'doc': {'content': '# This is a Kubernetes deployment configuration written in YAML, used to manage an application within a Kubernetes cluster. The deployment named \"nginx-deployment\" specifies the creation of three pod replicas running the Nginx web server. The configuration uses the \"nginx:1.14.2\" Docker image and exposes port 80 inside each container, allowing web traffic to be served. The selector and labels ensure the deployment manages the correct pods labeled with \"app: nginx.\" Overall, this configuration automates the deployment, scaling, and management of multiple Nginx instances for load handling or high availability.\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: nginx-deployment\\n  labels:\\n    app: nginx\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      app: nginx\\n  template:\\n    metadata:\\n      labels:\\n        app: nginx\\n    spec:\\n      containers:\\n      - name: nginx\\n        image: nginx:1.14.2\\n        ports:\\n        - containerPort: 80\\n',\n",
       "   'subchunk': '1/1',\n",
       "   'summary': 'This is a Kubernetes deployment configuration written in YAML, used to manage an application within a Kubernetes cluster. The deployment named \"nginx-deployment\" specifies the creation of three pod replicas running the Nginx web server. The configuration uses the \"nginx:1.14.2\" Docker image and exposes port 80 inside each container, allowing web traffic to be served. The selector and labels ensure the deployment manages the correct pods labeled with \"app: nginx.\" Overall, this configuration automates the deployment, scaling, and management of multiple Nginx instances for load handling or high availability.',\n",
       "   'chunk': '1/1',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\website-main\\\\content\\\\en\\\\examples\\\\controllers\\\\nginx-deployment.yaml'},\n",
       "  'score': 0.74609375},\n",
       " {'doc': {'content': '# The provided content is a Kubernetes deployment configuration written in YAML. It defines a Deployment resource that manages three replicas of an Nginx web server container, ensuring high availability and load balancing. The deployment specifies the use of the Nginx version 1.12 image, exposing port 80 for incoming TCP traffic. Resource requests and limits are set to allocate 50 millicores of CPU initially, with a maximum of 100 millicores, helping manage resource usage effectively. Overall, this configuration automates the deployment and scaling of Nginx containers within a Kubernetes cluster.\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  labels:\\n  name: nginx\\n  namespace:\\nspec:\\n  replicas: 3\\n  selector:\\n    matchLabels:\\n      run: nginx\\n  template:\\n    metadata:\\n      labels:\\n        run: nginx\\n    spec:\\n      containers:\\n      - image: nginx:1.12\\n        name: nginx\\n        ports:\\n        - containerPort: 80\\n          protocol: TCP\\n        resources:\\n          requests:\\n            cpu: 50m\\n          limits:\\n            cpu: 100m\\n',\n",
       "   'chunk': '1/1',\n",
       "   'summary': 'The provided content is a Kubernetes deployment configuration written in YAML. It defines a Deployment resource that manages three replicas of an Nginx web server container, ensuring high availability and load balancing. The deployment specifies the use of the Nginx version 1.12 image, exposing port 80 for incoming TCP traffic. Resource requests and limits are set to allocate 50 millicores of CPU initially, with a maximum of 100 millicores, helping manage resource usage effectively. Overall, this configuration automates the deployment and scaling of Nginx containers within a Kubernetes cluster.',\n",
       "   'filename': 'knowledge\\\\kubernetes\\\\kubernetes-lab-tutorial-master\\\\examples\\\\monitoring\\\\nginx-deploy.yaml',\n",
       "   'subchunk': '1/1'},\n",
       "  'score': 0.74609375}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_results = late_chunking_helper.re_rank(query=query, docs=rag_results, top_k=10)\n",
    "ranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e984994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:8080/v1/meta \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://pypi.org/pypi/weaviate-client/json \"HTTP/1.1 200 OK\"\n",
      "d:\\Python\\MasterIA\\TFM\\test_folder\\.venv\\lib\\site-packages\\weaviate\\warnings.py:314: ResourceWarning: Con004: The connection to Weaviate was not closed properly. This can lead to memory leaks.\n",
      "            Please make sure to close the connection using `client.close()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Object(uuid=_WeaviateUUIDInt('5dd3f31c-5e73-4bdb-b099-e7fcf1eb1acb'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'content': '## {{% heading \"whatsnext\" %}}  \\n* Read the [kubectl overview](/docs/reference/kubectl/) and learn about [JsonPath](/docs/reference/kubectl/jsonpath).  \\n* See [kubectl](/docs/reference/kubectl/kubectl/) options.  \\n* Also read [kubectl Usage Conventions](/docs/reference/kubectl/conventions/) to understand how to use kubectl in reusable scripts.  \\n* See more community [kubectl cheatsheets](https://github.com/dennyzhang/cheatsheet-kubernetes-A4).', 'filename': 'knowledge/kubernetes/website-main/content/en/docs/reference/kubectl/quick-reference.md', 'chunk': '23/23', 'subchunk': '1/1'}, references=None, vector={}, collection='Test'),\n",
       " Object(uuid=_WeaviateUUIDInt('dc2a97aa-b075-49f4-a7ca-1efaeb886585'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'content': '## Kubectl autocomplete  \\n### BASH  \\n```bash\\nsource <(kubectl completion bash) # set up autocomplete in bash into the current shell, bash-completion package should be installed first.\\necho \"source <(kubectl completion bash)\" >> ~/.bashrc # add autocomplete permanently to your bash shell.\\n```  \\nYou can also use a shorthand alias for `kubectl` that also works with completion:  \\n```bash\\nalias k=kubectl\\ncomplete -o default -F __start_kubectl k\\n```  \\n### ZSH  \\n```bash\\nsource <(kubectl completion zsh)  # set up autocomplete in zsh into the current shell\\necho \\'[[ $commands[kubectl] ]] && source <(kubectl completion zsh)\\' >> ~/.zshrc # add autocomplete permanently to your zsh shell\\n```  \\n### FISH  \\n{{< note >}}\\nRequires kubectl version 1.23 or above.\\n{{< /note >}}  \\n```bash\\necho \\'kubectl completion fish | source\\' > ~/.config/fish/completions/kubectl.fish && source ~/.config/fish/completions/kubectl.fish\\n```  \\n### A note on `--all-namespaces`  \\nAppending `--all-namespaces` happens frequently enough that you should be aware of the shorthand for `--all-namespaces`:  \\n```kubectl -A```', 'filename': 'knowledge/kubernetes/website-main/content/en/docs/reference/kubectl/quick-reference.md', 'chunk': '2/23', 'subchunk': '1/1'}, references=None, vector={}, collection='Test'),\n",
       " Object(uuid=_WeaviateUUIDInt('7b17d2ce-0c4b-41a3-988d-66ce28ba9389'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'content': '# List Names of Pods that belong to Particular RC\\n# \"jq\" command useful for transformations that are too complex for jsonpath, it can be found at https://jqlang.github.io/jq/\\nsel=${$(kubectl get rc my-rc --output=json | jq -j \\'.spec.selector | to_entries | .[] | \"\\\\(.key)=\\\\(.value),\"\\')%?}\\necho $(kubectl get pods --selector=$sel --output=jsonpath={.items..metadata.name})\\n\\n# Show labels for all pods (or any other Kubernetes object that supports labelling)\\nkubectl get pods --show-labels\\n\\n# Check which nodes are ready\\nJSONPATH=\\'{range .items[*]}{@.metadata.name}:{range @.status.conditions[*]}{@.type}={@.status};{end}{end}\\' \\\\\\n&& kubectl get nodes -o jsonpath=\"$JSONPATH\" | grep \"Ready=True\"\\n\\n# Check which nodes are ready with custom-columns\\nkubectl get node -o custom-columns=\\'NODE_NAME:.metadata.name,STATUS:.status.conditions[?(@.type==\"Ready\")].status\\'\\n\\n# Output decoded secrets without external tools\\nkubectl get secret my-secret -o go-template=\\'{{range $k,$v := .data}}{{\"### \"}}{{$k}}{{\"\\\\n\"}}{{$v|base64decode}}{{\"\\\\n\\\\n\"}}{{end}}\\'\\n\\n# List all Secrets currently in use by a pod\\nkubectl get pods -o json | jq \\'.items[].spec.containers[].env[]?.valueFrom.secretKeyRef.name\\' | grep -v null | sort | uniq\\n\\n# List all containerIDs of initContainer of all pods\\n# Helpful when cleaning up stopped containers, while avoiding removal of initContainers.\\nkubectl get pods --all-namespaces -o jsonpath=\\'{range .items[*].status.initContainerStatuses[*]}{.containerID}{\"\\\\n\"}{end}\\' | cut -d/ -f3\\n\\n# List Events sorted by timestamp\\nkubectl get events --sort-by=.metadata.creationTimestamp\\n\\n# List all warning events\\nkubectl events --types=Warning\\n\\n# Compares the current state of the cluster against the state that the cluster would be in if the manifest was applied.\\nkubectl diff -f ./my-manifest.yaml\\n\\n# Produce a period-delimited tree of all keys returned for nodes\\n# Helpful when locating a key within a complex nested JSON structure\\nkubectl get nodes -o json | jq -c \\'paths|join(\".\")\\'', 'chunk': '8/23', 'subchunk': '2/3', 'filename': 'knowledge/kubernetes/website-main/content/en/docs/reference/kubectl/quick-reference.md'}, references=None, vector={}, collection='Test')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from weaviate.classes.query import Filter\n",
    "\n",
    "with weaviate_helper.connect() as client:\n",
    "    collection = client.collections.get(name=\"test\")\n",
    "    response = collection.query.fetch_objects(\n",
    "    filters=Filter.by_property(\"filename\").like(\"*quick-reference.md*\"),\n",
    "    limit=3\n",
    ")\n",
    "response.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db1ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
